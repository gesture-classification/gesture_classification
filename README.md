# Motorica Advanced Gesture Classification

## Оглавление

* [Введение](README.md#Введение)
* [Структура проекта](README.md#Структура-проекта)
* [Экспериментальные данные и методы](README.md#Экспериментальные-данные-и-методы)
* [Установка](README.md#Установка)
* [Подготовка и анализ данных](README.md#Подготовка-и-анализ-данных)
* [Структура моделей машинного обучения](README.md#Структура-моделей-машинного-обучения)
* [Лог эксперимента](README.md#лог-эксперимента)
* [Выводы](README.md#выводы)


## Введение

Вследствие потери органа или части тела функции человека существенно ограничиваются. Благодяря прогрессу в области биомедицины и изобретению таких протезов, как: аппарат ИВЛ, сердечный клапан и бионические протезы конечностей, и т. д., утраченные функции организма могут быть частично восстановлены. Соотношение замещеннных функциий к исходным зависит от многих факторов: сложности утраченного органа, исходного количества его функций и их вариабельности. Так, например, в виду многообразия жестов кисти, высокой её точности и скорости протезирование кистей рук является сложной задачей. Ввиду значительного влияния на качество жизни необходимость бионических протезов кисти очень высока.

По [данным](https://rosstat.gov.ru/storage/mediabank/ST90u1EJ/2-30.doc) РосСтата на 2020г количество больных, нуждающихся в протезировании кисти, составляется около 1.5% (примерно 2600 человек) от всех нуждающихся в протезировании. Для улучшения функционала бионических кистевых протезов компанией ["Моторика"](https://motorica.org/) была предложена [задача](https://www.kaggle.com/competitions/motorica-advanced-gesture-classification) «распознавания жестов» на основании данных оптомиографических датчиков.

В ходе соревнования на Kaggle нами была создана математическая модель, предсказывающая жест человека по сокращению мышц кисти. Задача исследования заключалась в следующем:
* классификация жеста по показаниям датчиков оптомиографии установленных на кисти;
* определение момента начала жеста.

<p align="center"> 
   <img src="/logs_and_figures/fig_0-1.PNG" height=300>
</p>


## Структура проекта

<details>
  <summary> Посмотреть структуру папок и файлов </summary>

```Python
gesture_classification
├── .git
├── .gitignore
├── data             # содержит архив с исходными данными
│   └── motorica-advanced-gesture-classification.zip
├── dockerfile
├── logs_and_figures # содержит графики, логи работы модели, сабмиты
│   ├── fig_0-1.PNG
...
│   ├── fig_2-5.png
│   ├── y_test_submit_rnn_LSTM(0.69641).csv
│   └── y_test_submit_rnn_LSTM.csv
├── main.py
├── models           # модели проекта и их коэффициенты 
│   ├── best_model_rnn_1.hdf5
│   ├── best_model_rnn_2.hdf5
│   ├── best_model_rnn_3.hdf5
│   ├── lstm.py
│   ├── model.py
│   ├── model_lstm_1
│   ├── model_lstm_2
│   ├── model_lstm_3
│   ├── srnn.py
│   ├── temp_best_model
│   └── weights
├── notebooks        # ноутбуки проекта
│   ├── .cometml-runs
│   ├── 1_EDA_sprint_3.ipynb
│   ├── 2_model_SRNN_LSTM.ipynb
│   └── 3_boxplots_clear_gests_sens_gest.ipynb
├── README.md
├── requirements.txt 
└── utils            # основные и вспомогательные функции, константы, загрузчик данных
    ├── credentials.json
    ├── data_reader.py
    ├── figures.py
    ├── functions.py
    ├── inference.py
    ├── __ init __.py
    └── __pycache__
```
</details>


## Экспериментальные данные и методы
Сбор данных был организован следующим образом: случайным образом было выбрано 3 человека-оператора со здоровыми руками, чтобы обеспечить достоверность показаний. Затем к коже их рук были прикреплены датчики, считывающие сокращение мышц методом оптомиографии. 

Оптомиография (ОМГ) - метод мониторинга мышечной активности с помощью оптических сигналов. ОМГ датичик периодически испускает импульсы в инфракрасном диапазоне на участок кожи. В случае если подкожная мышца расслаблена, то луч от датчика будет отражаться от поверхности кожи на приёмник-фототранзистор; в случае расслабления - в значительно поглащаться мышцей (Рис.1-2). Степень поглащения является показателем уровня напряжения мышцы.
 
<p align="center"> <img src="/logs_and_figures/fig_0-2_ru.png" height=250> <br> Рис.1-1 - Схема детектирования состояния мышцы оптомиогарфическими датчиком </p>

Оператор циклически выполнял одинаковую последовательность жестов, которую ему демонстрировали. Поскольку оператор тратил некоторое время на принятие решения о выполнении показанного жеста, то его жесты выполнялись с некоторой задержкой относительно показанных. Важно, что по условиям эксперимента исходное либо конечное состояние кисти - жест "открытая ладонь". Кроме того, из многообразия жестов были выбраны только характерные положения сгиба и разгиба пальцев для упрощения распознавания. Сигналы манипулятора были записаны файлы y_train, а сигналы с датчиков оптомиографии были записаны в файлы X_train и X_test. 

<p align="center">   <img src="/logs_and_figures/fig_2-1.png"> Рис.1-2 - Экспериментальные данные.</p>  

:arrow_up:[Оглавление](README.md#оглавление)

## Установка
1. Скопируйте репозиторий, введя в терминале следующие команды:
```Python
# Clone repository and install requirements

git clone https://github.com/gesture-classification/gesture_classification
pip install -r -q requirements.txt
``` 
2. Переместите архив с данными для обучения (X_train) и валидации (X_test)  в папку *data*. 
3. Выполните в терминале команду ```python main.py```

## Подготовка и анализ данных

Тренировочные и тестовые данные каждого пилота загружаются из архива. Они преобразуются с помощью библиотеки [*mne*](https://mne.tools/stable/index.html).

По результатам анализа сделаны следующие выводы:
* удаление "нечитаемых" участков (класс жеста "-1") позволяет легко избавиться от "битых" данных
* можно выделить характерные уровни сигнала датчиков при каждом жесте ( см. файл [*3_boxplots_clear_gests_sens_gest.ipynb*](https://github.com/gesture-classification/gesture_classification/blob/main/notebooks/3_boxplots_clear_gests_sens_gest.ipynb)
* датчики можно разделить по величине на активные и пассивные (см. Рис.1-3);
<p align="center">   <img src="/logs_and_figures/fig_1-3.png"> </p>  

* нормализация сигналов датчиков и взятии производной от функции не позволил однозначно определить временной интервал начала жеста (см. Рис. 1-5).
<p align="center">   <img src="/logs_and_figures/fig_1-5.png"> </p>

Сравнительный анализ предсказаний моделей до и после предобработки показал, что все методы, кроме первого, ухудшают качество предсказания. Поэтому было решено отказаться от второго этапа и обучать модель на "сырых" данных. ([*см. ноутбук 1_EDA_sprint_3.ipynb*](https://github.com/gesture-classification/gesture_classification/blob/main/notebooks/1_EDA_sprint_3.ipynb)). 

:arrow_up:[Оглавление](README.md#оглавление)

## Структура моделей машинного обучения

Наборы тренировочных и тестовых данных каждого пилота поступают на параллельное обучение двух моделей, имеющих одинаковую структуру и набор параметров: 
- SimpleRNN, задача которой предсказать фактический момент изменения жеста (появление "ступеньки");
- LSTM, которая предсказывает класс жеста с учётом времени начала жеста, определённого первой моделью. 


**Модель SimpleRNN** из библиотеки [*Keras*](https://keras.io/) имеет простую структуру из одного слоя. Чтобы компенсировать ошибки предсказания, обучение модели для каждого "пилота" проводится несколько раз с разными параметрами validation_split и затем результаты предсказания каждой модели усредняются по каждому пилоту. Ошибка предсказания определяется по среднеквадратическому отклонению. Ход обучения модели показан на рис. 2-2.


![график обучения первой модели](/logs_and_figures/fig_2-2.png)
<p align="center">  Рис.2-2 - график обучения модели SimpleRNN. </p>


Как видно из Рис. 2-2, качество предсказания данных валидационной выборки практически не изменяется. С другой стороны, модель успешно предсказывает временной промежуток начала жеста.



**Модель LSTM** состоит из нескольких слоев LSTM с дополнительным Dense-слоем. Структура слоёв модели подбиралась эмпирически по оценке f1-score. Обучение модели производится на оригинальных данных X_train и корректированных данных y_train_ch. Затем обученная модель LSTM используется для предсказания тестовых данных.

По наклону кривой обучения на рис.2-4 видно, что модель переобучается. Неоптимально выбранные параметры обучения повышают время обучения и снижают точность предсказании тестовых данных. Однако, полученный результат f1-score составляет 0.69632.

![график обучения второй модели](/logs_and_figures/fig_2-4.png)

<p align="center">  Рис.2-4 - график обучения модели LSTM. </p>

Результат предсказания представлен на рис. 2-5.

![график обучения второй модели](/logs_and_figures/fig_2-5.png)

<p align="center">  Рис.2-5 - график обучения модели LSTM. </p>

:arrow_up:[Оглавление](README.md#оглавление)

## Лог эксперимента

Логгирование параметров и хода обучения модели, а также графиков выполнено с момощью библитокеи Comet_ml. Результаты эсперимента доступны [на сайте Comet_ml](https://www.comet.com/alex1iv/gesture-classification/view/new/panels).


## Выводы
В результате исследования разработана программа предобработки данных и создания модели предсказания жестов по мускульному сигналу предплечья человека. Данную модель возможно использовать для создания автоматизированных протезов кисти.

:arrow_up:[Оглавление](README.md#оглавление)